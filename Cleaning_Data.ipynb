{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Financial Data\n",
    "import yfinance as yf\n",
    "\n",
    "# Technical Analysis\n",
    "import ta\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Backtesting\n",
    "import backtrader as bt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 100 Stocks over the past 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ATVI: possibly delisted; no timezone found\n",
      "C:\\Users\\Sezy\\AppData\\Local\\Temp\\ipykernel_33544\\2875241900.py:33: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_data = pd.concat([all_data, historical_data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Ticker                      Date        Open        High         Low  \\\n",
      "0        MSFT 2020-01-02 00:00:00-05:00  151.870762  153.735906  151.440346   \n",
      "1        MSFT 2020-01-03 00:00:00-05:00  151.430809  152.989871  151.182113   \n",
      "2        MSFT 2020-01-06 00:00:00-05:00  150.244705  152.176809  149.699501   \n",
      "3        MSFT 2020-01-07 00:00:00-05:00  152.387267  152.722028  150.474296   \n",
      "4        MSFT 2020-01-08 00:00:00-05:00  152.014192  153.802829  151.076840   \n",
      "...       ...                       ...         ...         ...         ...   \n",
      "149287   DKNG 2025-01-23 00:00:00-05:00   40.770000   41.535000   40.250000   \n",
      "149288   DKNG 2025-01-24 00:00:00-05:00   41.570000   42.000000   41.090000   \n",
      "149289   DKNG 2025-01-27 00:00:00-05:00   40.500000   41.455002   40.070000   \n",
      "149290   DKNG 2025-01-28 00:00:00-05:00   41.250000   42.279999   41.230000   \n",
      "149291   DKNG 2025-01-29 00:00:00-05:00   42.200001   42.305000   41.200001   \n",
      "\n",
      "             Close      Volume  \n",
      "0       153.630692  22622100.0  \n",
      "1       151.717743  21116200.0  \n",
      "2       152.109848  20813700.0  \n",
      "3       150.722977  21634100.0  \n",
      "4       153.123718  27746500.0  \n",
      "...            ...         ...  \n",
      "149287   41.509998   3781800.0  \n",
      "149288   41.340000   4881400.0  \n",
      "149289   41.110001   5941600.0  \n",
      "149290   42.000000   6114900.0  \n",
      "149291   41.900002   4018200.0  \n",
      "\n",
      "[149292 rows x 7 columns]\n",
      "Data saved to top_10_stocks_2024.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of the top 10 ticker symbols\n",
    "ticker_symbols = [ \"MSFT\", \"AAPL\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"SPY\", \"V\", \"AMD\",\n",
    "    \"NVDA\", \"INTC\", \"CSCO\", \"WMT\", \"DIS\", \"MCD\", \"BA\", \"PYPL\", \"SNAP\", \"NKE\",\n",
    "    \"XOM\", \"CVX\", \"JNJ\", \"PFE\", \"BABA\", \"T\", \"VZ\", \"GE\", \"IBM\", \"GS\", \"JPM\",\n",
    "    \"MS\", \"GS\", \"UNH\", \"CVS\", \"HD\", \"LOW\", \"UPS\", \"SBUX\", \"BLK\", \"DELL\", \"LMT\",\n",
    "    \"ABT\", \"TXN\", \"TMO\", \"MRK\", \"AMAT\", \"INTU\", \"ADI\", \"MU\", \"LULU\", \"PLUG\",\n",
    "    \"F\", \"GM\", \"COF\", \"STZ\", \"KMX\", \"TSCO\", \"LMT\", \"SHOP\", \"SQ\", \"BIDU\", \"SPG\",\n",
    "    \"MELI\", \"BA\", \"ATVI\", \"GS\", \"CAT\", \"HLT\", \"TGT\", \"DOW\", \"COP\", \"BA\", \"NKE\",\n",
    "    \"LULU\", \"GS\", \"JNJ\", \"JPM\", \"BRK-A\", \"MSFT\", \"V\", \"TSLA\", \"XOM\", \"PFE\",\n",
    "    \"WMT\", \"GE\", \"T\", \"VZ\", \"AMZN\", \"BABA\", \"CSCO\", \"NVDA\", \"AAPL\", \"GOOGL\", \"INTC\",\n",
    "    \"AMT\", \"CVX\", \"META\", \"WFC\", \"KO\", \"PEP\", \"K\", \"SBUX\", \"NKE\", \"LOW\", \"MCD\",\n",
    "    \"DIS\", \"WMT\", \"XOM\", \"UPS\", \"HD\", \"TMO\", \"PYPL\", \"UBER\", \"ZM\", \"TEAM\", \"MDB\",\n",
    "    \"DKNG\"]\n",
    "\n",
    "# Create an empty DataFrame to store all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker symbol and fetch data\n",
    "for ticker_symbol in ticker_symbols:\n",
    "    # Create a Ticker object for each stock\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "    # Fetch historical market data from 2024 to the present\n",
    "    historical_data = ticker.history(start=\"2020-01-01\", end=pd.to_datetime(\"today\").strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Add a new column 'Ticker' with the ticker symbol for each row\n",
    "    historical_data['Ticker'] = ticker_symbol\n",
    "\n",
    "    # Append the data to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, historical_data])\n",
    "\n",
    "# Reset the index after combining all the data\n",
    "all_data.reset_index(inplace=True)\n",
    "\n",
    "# Display the first few rows of the combined data\n",
    "print(all_data[['Ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "\n",
    "# Optionally, save the data to a CSV file\n",
    "all_data.to_csv('top_10_stocks_2024.csv', index=False)\n",
    "print(\"Data saved to top_10_stocks_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE STOCKS INFO\n",
    "Ran to update MongoDatabase daily, collecting most recent stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking latest data for MSFT...\n",
      "📈 Fetching new data for MSFT from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MSFT: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for MSFT, skipping...\n",
      "🔍 Checking latest data for AAPL...\n",
      "📈 Fetching new data for AAPL from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for AAPL\n",
      "🔍 Checking latest data for GOOGL...\n",
      "📈 Fetching new data for GOOGL from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for GOOGL\n",
      "🔍 Checking latest data for AMZN...\n",
      "📈 Fetching new data for AMZN from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for AMZN\n",
      "🔍 Checking latest data for TSLA...\n",
      "📈 Fetching new data for TSLA from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TSLA\n",
      "🔍 Checking latest data for META...\n",
      "📈 Fetching new data for META from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for META\n",
      "🔍 Checking latest data for NVDA...\n",
      "📈 Fetching new data for NVDA from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for NVDA\n",
      "🔍 Checking latest data for SPY...\n",
      "📈 Fetching new data for SPY from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SPY\n",
      "🔍 Checking latest data for V...\n",
      "📈 Fetching new data for V from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for V\n",
      "🔍 Checking latest data for AMD...\n",
      "📈 Fetching new data for AMD from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for AMD\n",
      "🔍 Checking latest data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NVDA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for NVDA from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for NVDA, skipping...\n",
      "🔍 Checking latest data for INTC...\n",
      "📈 Fetching new data for INTC from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for INTC\n",
      "🔍 Checking latest data for CSCO...\n",
      "📈 Fetching new data for CSCO from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for CSCO\n",
      "🔍 Checking latest data for WMT...\n",
      "📈 Fetching new data for WMT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for WMT\n",
      "🔍 Checking latest data for DIS...\n",
      "📈 Fetching new data for DIS from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for DIS\n",
      "🔍 Checking latest data for MCD...\n",
      "📈 Fetching new data for MCD from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MCD\n",
      "🔍 Checking latest data for BA...\n",
      "📈 Fetching new data for BA from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for BA\n",
      "🔍 Checking latest data for PYPL...\n",
      "📈 Fetching new data for PYPL from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for PYPL\n",
      "🔍 Checking latest data for SNAP...\n",
      "📈 Fetching new data for SNAP from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SNAP\n",
      "🔍 Checking latest data for NKE...\n",
      "📈 Fetching new data for NKE from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for NKE\n",
      "🔍 Checking latest data for XOM...\n",
      "📈 Fetching new data for XOM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for XOM\n",
      "🔍 Checking latest data for CVX...\n",
      "📈 Fetching new data for CVX from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for CVX\n",
      "🔍 Checking latest data for JNJ...\n",
      "📈 Fetching new data for JNJ from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for JNJ\n",
      "🔍 Checking latest data for PFE...\n",
      "📈 Fetching new data for PFE from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for PFE\n",
      "🔍 Checking latest data for BABA...\n",
      "📈 Fetching new data for BABA from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for BABA\n",
      "🔍 Checking latest data for T...\n",
      "📈 Fetching new data for T from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for T\n",
      "🔍 Checking latest data for VZ...\n",
      "📈 Fetching new data for VZ from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for VZ\n",
      "🔍 Checking latest data for GE...\n",
      "📈 Fetching new data for GE from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for GE\n",
      "🔍 Checking latest data for IBM...\n",
      "📈 Fetching new data for IBM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for IBM\n",
      "🔍 Checking latest data for GS...\n",
      "📈 Fetching new data for GS from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for GS\n",
      "🔍 Checking latest data for JPM...\n",
      "📈 Fetching new data for JPM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for JPM\n",
      "🔍 Checking latest data for MS...\n",
      "📈 Fetching new data for MS from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MS\n",
      "🔍 Checking latest data for GS...\n",
      "📈 Fetching new data for GS from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GS: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for GS, skipping...\n",
      "🔍 Checking latest data for UNH...\n",
      "📈 Fetching new data for UNH from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for UNH\n",
      "🔍 Checking latest data for CVS...\n",
      "📈 Fetching new data for CVS from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for CVS\n",
      "🔍 Checking latest data for HD...\n",
      "📈 Fetching new data for HD from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for HD\n",
      "🔍 Checking latest data for LOW...\n",
      "📈 Fetching new data for LOW from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for LOW\n",
      "🔍 Checking latest data for UPS...\n",
      "📈 Fetching new data for UPS from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for UPS\n",
      "🔍 Checking latest data for SBUX...\n",
      "📈 Fetching new data for SBUX from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SBUX\n",
      "🔍 Checking latest data for BLK...\n",
      "📈 Fetching new data for BLK from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for BLK\n",
      "🔍 Checking latest data for DELL...\n",
      "📈 Fetching new data for DELL from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for DELL\n",
      "🔍 Checking latest data for LMT...\n",
      "📈 Fetching new data for LMT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for LMT\n",
      "🔍 Checking latest data for ABT...\n",
      "📈 Fetching new data for ABT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for ABT\n",
      "🔍 Checking latest data for TXN...\n",
      "📈 Fetching new data for TXN from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TXN\n",
      "🔍 Checking latest data for TMO...\n",
      "📈 Fetching new data for TMO from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TMO\n",
      "🔍 Checking latest data for MRK...\n",
      "📈 Fetching new data for MRK from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MRK\n",
      "🔍 Checking latest data for AMAT...\n",
      "📈 Fetching new data for AMAT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for AMAT\n",
      "🔍 Checking latest data for INTU...\n",
      "📈 Fetching new data for INTU from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for INTU\n",
      "🔍 Checking latest data for ADI...\n",
      "📈 Fetching new data for ADI from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for ADI\n",
      "🔍 Checking latest data for MU...\n",
      "📈 Fetching new data for MU from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MU\n",
      "🔍 Checking latest data for LULU...\n",
      "📈 Fetching new data for LULU from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for LULU\n",
      "🔍 Checking latest data for PLUG...\n",
      "📈 Fetching new data for PLUG from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for PLUG\n",
      "🔍 Checking latest data for F...\n",
      "📈 Fetching new data for F from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for F\n",
      "🔍 Checking latest data for GM...\n",
      "📈 Fetching new data for GM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for GM\n",
      "🔍 Checking latest data for COF...\n",
      "📈 Fetching new data for COF from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for COF\n",
      "🔍 Checking latest data for STZ...\n",
      "📈 Fetching new data for STZ from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for STZ\n",
      "🔍 Checking latest data for KMX...\n",
      "📈 Fetching new data for KMX from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for KMX\n",
      "🔍 Checking latest data for TSCO...\n",
      "📈 Fetching new data for TSCO from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TSCO\n",
      "🔍 Checking latest data for LMT...\n",
      "📈 Fetching new data for LMT from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LMT: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for LMT, skipping...\n",
      "🔍 Checking latest data for SHOP...\n",
      "📈 Fetching new data for SHOP from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SHOP\n",
      "🔍 Checking latest data for SQ...\n",
      "📈 Fetching new data for SQ from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SQ\n",
      "🔍 Checking latest data for BIDU...\n",
      "📈 Fetching new data for BIDU from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for BIDU\n",
      "🔍 Checking latest data for SPG...\n",
      "📈 Fetching new data for SPG from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for SPG\n",
      "🔍 Checking latest data for MELI...\n",
      "📈 Fetching new data for MELI from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MELI\n",
      "🔍 Checking latest data for BA...\n",
      "📈 Fetching new data for BA from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for BA, skipping...\n",
      "🔍 Checking latest data for ATVI...\n",
      "📈 Fetching new data for ATVI from 2020-02-06 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ATVI: possibly delisted; no timezone found\n",
      "$GS: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for ATVI, skipping...\n",
      "🔍 Checking latest data for GS...\n",
      "📈 Fetching new data for GS from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for GS, skipping...\n",
      "🔍 Checking latest data for CAT...\n",
      "📈 Fetching new data for CAT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for CAT\n",
      "🔍 Checking latest data for HLT...\n",
      "📈 Fetching new data for HLT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for HLT\n",
      "🔍 Checking latest data for TGT...\n",
      "📈 Fetching new data for TGT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TGT\n",
      "🔍 Checking latest data for DOW...\n",
      "📈 Fetching new data for DOW from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for DOW\n",
      "🔍 Checking latest data for COP...\n",
      "📈 Fetching new data for COP from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for COP\n",
      "🔍 Checking latest data for BA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for BA from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for BA, skipping...\n",
      "🔍 Checking latest data for NKE...\n",
      "📈 Fetching new data for NKE from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NKE: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$LULU: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for NKE, skipping...\n",
      "🔍 Checking latest data for LULU...\n",
      "📈 Fetching new data for LULU from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for LULU, skipping...\n",
      "🔍 Checking latest data for GS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GS: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for GS from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for GS, skipping...\n",
      "🔍 Checking latest data for JNJ...\n",
      "📈 Fetching new data for JNJ from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JNJ: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for JNJ, skipping...\n",
      "🔍 Checking latest data for JPM...\n",
      "📈 Fetching new data for JPM from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JPM: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for JPM, skipping...\n",
      "🔍 Checking latest data for BRK-A...\n",
      "📈 Fetching new data for BRK-A from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for BRK-A\n",
      "🔍 Checking latest data for MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MSFT: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for MSFT from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for MSFT, skipping...\n",
      "🔍 Checking latest data for V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$V: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for V from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for V, skipping...\n",
      "🔍 Checking latest data for TSLA...\n",
      "📈 Fetching new data for TSLA from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TSLA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for TSLA, skipping...\n",
      "🔍 Checking latest data for XOM...\n",
      "📈 Fetching new data for XOM from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XOM: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$PFE: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for XOM, skipping...\n",
      "🔍 Checking latest data for PFE...\n",
      "📈 Fetching new data for PFE from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for PFE, skipping...\n",
      "🔍 Checking latest data for WMT...\n",
      "📈 Fetching new data for WMT from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WMT: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for WMT, skipping...\n",
      "🔍 Checking latest data for GE...\n",
      "📈 Fetching new data for GE from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GE: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for GE, skipping...\n",
      "🔍 Checking latest data for T...\n",
      "📈 Fetching new data for T from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$T: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$VZ: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for T, skipping...\n",
      "🔍 Checking latest data for VZ...\n",
      "📈 Fetching new data for VZ from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for VZ, skipping...\n",
      "🔍 Checking latest data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AMZN: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for AMZN from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for AMZN, skipping...\n",
      "🔍 Checking latest data for BABA...\n",
      "📈 Fetching new data for BABA from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BABA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$CSCO: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for BABA, skipping...\n",
      "🔍 Checking latest data for CSCO...\n",
      "📈 Fetching new data for CSCO from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for CSCO, skipping...\n",
      "🔍 Checking latest data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NVDA: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for NVDA from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for NVDA, skipping...\n",
      "🔍 Checking latest data for AAPL...\n",
      "📈 Fetching new data for AAPL from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AAPL: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$GOOGL: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for AAPL, skipping...\n",
      "🔍 Checking latest data for GOOGL...\n",
      "📈 Fetching new data for GOOGL from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for GOOGL, skipping...\n",
      "🔍 Checking latest data for INTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INTC: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for INTC from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for INTC, skipping...\n",
      "🔍 Checking latest data for AMT...\n",
      "📈 Fetching new data for AMT from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for AMT\n",
      "🔍 Checking latest data for CVX...\n",
      "📈 Fetching new data for CVX from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CVX: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$META: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for CVX, skipping...\n",
      "🔍 Checking latest data for META...\n",
      "📈 Fetching new data for META from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for META, skipping...\n",
      "🔍 Checking latest data for WFC...\n",
      "📈 Fetching new data for WFC from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for WFC\n",
      "🔍 Checking latest data for KO...\n",
      "📈 Fetching new data for KO from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for KO\n",
      "🔍 Checking latest data for PEP...\n",
      "📈 Fetching new data for PEP from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for PEP\n",
      "🔍 Checking latest data for K...\n",
      "📈 Fetching new data for K from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for K\n",
      "🔍 Checking latest data for SBUX...\n",
      "📈 Fetching new data for SBUX from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SBUX: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$NKE: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for SBUX, skipping...\n",
      "🔍 Checking latest data for NKE...\n",
      "📈 Fetching new data for NKE from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for NKE, skipping...\n",
      "🔍 Checking latest data for LOW...\n",
      "📈 Fetching new data for LOW from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LOW: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for LOW, skipping...\n",
      "🔍 Checking latest data for MCD...\n",
      "📈 Fetching new data for MCD from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MCD: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for MCD, skipping...\n",
      "🔍 Checking latest data for DIS...\n",
      "📈 Fetching new data for DIS from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DIS: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$WMT: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$XOM: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for DIS, skipping...\n",
      "🔍 Checking latest data for WMT...\n",
      "📈 Fetching new data for WMT from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for WMT, skipping...\n",
      "🔍 Checking latest data for XOM...\n",
      "📈 Fetching new data for XOM from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for XOM, skipping...\n",
      "🔍 Checking latest data for UPS...\n",
      "📈 Fetching new data for UPS from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$UPS: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for UPS, skipping...\n",
      "🔍 Checking latest data for HD...\n",
      "📈 Fetching new data for HD from 2025-02-01 to 2025-02-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HD: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n",
      "$TMO: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No new data found for HD, skipping...\n",
      "🔍 Checking latest data for TMO...\n",
      "📈 Fetching new data for TMO from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for TMO, skipping...\n",
      "🔍 Checking latest data for PYPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PYPL: possibly delisted; no price data found  (1d 2025-02-01 -> 2025-02-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching new data for PYPL from 2025-02-01 to 2025-02-03...\n",
      "⚠️ No new data found for PYPL, skipping...\n",
      "🔍 Checking latest data for UBER...\n",
      "📈 Fetching new data for UBER from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for UBER\n",
      "🔍 Checking latest data for ZM...\n",
      "📈 Fetching new data for ZM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for ZM\n",
      "🔍 Checking latest data for TEAM...\n",
      "📈 Fetching new data for TEAM from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for TEAM\n",
      "🔍 Checking latest data for MDB...\n",
      "📈 Fetching new data for MDB from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for MDB\n",
      "🔍 Checking latest data for DKNG...\n",
      "📈 Fetching new data for DKNG from 2025-01-30 to 2025-02-03...\n",
      "✅ Updated 2 new entries for DKNG\n",
      "🎉 Stock data update complete!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "import yfinance as yf\n",
    "from dateutil import parser\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Stock_Data\"]\n",
    "collection = db[\"Stock_5year\"]\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# List of 100 ticker symbols (Your original list)\n",
    "ticker_symbols = [ \n",
    "    \"MSFT\", \"AAPL\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"SPY\", \"V\", \"AMD\",\n",
    "    \"NVDA\", \"INTC\", \"CSCO\", \"WMT\", \"DIS\", \"MCD\", \"BA\", \"PYPL\", \"SNAP\", \"NKE\",\n",
    "    \"XOM\", \"CVX\", \"JNJ\", \"PFE\", \"BABA\", \"T\", \"VZ\", \"GE\", \"IBM\", \"GS\", \"JPM\",\n",
    "    \"MS\", \"GS\", \"UNH\", \"CVS\", \"HD\", \"LOW\", \"UPS\", \"SBUX\", \"BLK\", \"DELL\", \"LMT\",\n",
    "    \"ABT\", \"TXN\", \"TMO\", \"MRK\", \"AMAT\", \"INTU\", \"ADI\", \"MU\", \"LULU\", \"PLUG\",\n",
    "    \"F\", \"GM\", \"COF\", \"STZ\", \"KMX\", \"TSCO\", \"LMT\", \"SHOP\", \"SQ\", \"BIDU\", \"SPG\",\n",
    "    \"MELI\", \"BA\", \"ATVI\", \"GS\", \"CAT\", \"HLT\", \"TGT\", \"DOW\", \"COP\", \"BA\", \"NKE\",\n",
    "    \"LULU\", \"GS\", \"JNJ\", \"JPM\", \"BRK-A\", \"MSFT\", \"V\", \"TSLA\", \"XOM\", \"PFE\",\n",
    "    \"WMT\", \"GE\", \"T\", \"VZ\", \"AMZN\", \"BABA\", \"CSCO\", \"NVDA\", \"AAPL\", \"GOOGL\", \"INTC\",\n",
    "    \"AMT\", \"CVX\", \"META\", \"WFC\", \"KO\", \"PEP\", \"K\", \"SBUX\", \"NKE\", \"LOW\", \"MCD\",\n",
    "    \"DIS\", \"WMT\", \"XOM\", \"UPS\", \"HD\", \"TMO\", \"PYPL\", \"UBER\", \"ZM\", \"TEAM\", \"MDB\",\n",
    "    \"DKNG\"\n",
    "]\n",
    "\n",
    "# Loop through each stock and update only missing data\n",
    "for ticker_symbol in ticker_symbols:\n",
    "    print(f\"🔍 Checking latest data for {ticker_symbol}...\")\n",
    "\n",
    "    # Get the most recent date for this stock in MongoDB\n",
    "    latest_entry = collection.find_one({\"Ticker\": ticker_symbol}, sort=[(\"Date\", -1)])\n",
    "\n",
    "    if latest_entry:\n",
    "        last_date_in_db = latest_entry[\"Date\"]\n",
    "        # Check if the last_date_in_db is a string and parse it\n",
    "        if isinstance(last_date_in_db, str):\n",
    "            last_date_in_db = parser.parse(last_date_in_db)\n",
    "    else:\n",
    "        # If no records exist, start from 5 years ago\n",
    "        last_date_in_db = datetime.today() - timedelta(days=5*365)\n",
    "\n",
    "    # Fetch only new data since the last recorded date\n",
    "    start_date = (last_date_in_db + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # If start_date is today, no need to fetch (already up to date)\n",
    "    if start_date >= today:\n",
    "        print(f\"✅ {ticker_symbol} is already up-to-date.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"📈 Fetching new data for {ticker_symbol} from {start_date} to {today}...\")\n",
    "\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    new_data = ticker.history(start=start_date, end=today)\n",
    "\n",
    "    if new_data.empty:\n",
    "        print(f\"⚠️ No new data found for {ticker_symbol}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Reset index & add ticker column\n",
    "    new_data.reset_index(inplace=True)\n",
    "    new_data[\"Ticker\"] = ticker_symbol\n",
    "\n",
    "    # Convert to dictionary format for MongoDB\n",
    "    records = new_data.to_dict(orient='records')\n",
    "\n",
    "    # Insert new records into MongoDB\n",
    "    collection.insert_many(records)\n",
    "    print(f\"✅ Updated {len(records)} new entries for {ticker_symbol}\")\n",
    "\n",
    "print(\"🎉 Stock data update complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting The Past 5 years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 149292 records into the database!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "df = pd.read_csv(r'C:\\Users\\Sezy\\OneDrive\\Personal_Projects\\Trading_Algorithm\\CSVFILES\\top_10_stocks_2024.csv')\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Default MongoDB URI\n",
    "db = client[\"Stock_Data\"]  # Replace with your desired database name\n",
    "collection = db[\"Stock_5year\"]  # Replace with your desired collection name\n",
    "\n",
    "# Convert DataFrame to dictionary and insert into MongoDB\n",
    "records = df.to_dict(orient='records')\n",
    "collection.insert_many(records)\n",
    "\n",
    "print(f\"Inserted {len(records)} records into the database!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
